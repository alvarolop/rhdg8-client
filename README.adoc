= Red Hat Data Grid 8 Java client
Álvaro López Medina <alopezme@redhat.com>
v1.0, 2020-12
// Create TOC wherever needed
:toc: macro
:sectanchors:
:sectnumlevels: 2
:sectnums: 
:source-highlighter: pygments
:imagesdir: images
// Start: Enable admonition icons
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
ifndef::env-github[]
:icons: font
endif::[]
// End: Enable admonition icons

This repository demonstrates how to connect to and use the latest release of Red Hat Data Grid 8.

// Create the Table of contents here
toc::[]



== Introduction

Red Hat Data Grid is an in-memory, distributed, NoSQL datastore solution. Your applications can access, process, and analyze data at in-memory speed to deliver a superior user experience. In the most common Data Grid deployment, you will have your DG client and server instances detached from each other.


This repository will focus on two main steps: 

* Creating caches on the server using several methods.
* Connecting to the Data Grid to perform basic functionality.

RHDG provides libraries in several programming languages to consume entries stored in the grid. However, in this section we will focus on the REST API, normally used for testing and occasional operations, and the highly-optimized HotRod Java client. These are the links to their documentation:

* https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.1/html-single/data_grid_rest_api/index[REST API].
* https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.1/html-single/hot_rod_java_client_guide/index[Hot Rod Java client].




WARNING: The following sections assume that you have a Red Hat Data Grid 8.1 server cluster running either on OCP or locally. For more information about configuring your cluster, check the following https://github.com/alvarolop/rhdg8-server[link].






== RHDG configuration

Add cache definitions to specify how Data Grid stores your data. You can create caches from configuration templates or from valid cache definitions in XML or JSON format through Data Grid Console, Data Grid CLI, Hot Rod clients, or Data Grid Operator. This section will explore three ways: Using the REST API, the CLI, and the `Cache` CRD.


=== Cache definition

First, define a cache using XML or JSON format. Bear in mind that name of the cache will be inherited from the REST URL or the CRD configuration, not from the cache configuration. The following JSON is an example of a cache configuration:

[source, json]
----
include::caches/distributed-01.json[]
----



=== Cache configuration using the REST API

If your DG is running on OCP, define these environment variables to simplify the following commands:
[source, bash]
----
CLUSTER_NAMESPACE="rhdg8"
CLUSTER_NAME="rhdg"
RHDG_URL=$(oc get route ${CLUSTER_NAME}-external -n ${CLUSTER_NAMESPACE} -o template='https://{{.spec.host}}')
CACHE_NAME="distributed-01"
----

If your DG is running locally, define these environment variables to simplify the following commands:
[source, bash]
----
RHDG_URL="http://localhost:11222"
CACHE_NAME="distributed-01"
----


*Create a cache*:
[source, bash]
----
curl -X POST -k -u developer:developer -H "Content-Type: application/json" ${RHDG_URL}/rest/v2/caches/${CACHE_NAME} --data-binary "@caches/$CACHE_NAME.json"
----


*Delete a cache*:

[source, bash]
----
curl -X DELETE -k -u developer:developer ${RHDG_URL}/rest/v2/caches/${CACHE_NAME} 
----


*Check a cache* configuration and status:
[source,bash]
----
curl -X GET -k -u developer:developer -H "Content-Type: application/json" ${RHDG_URL}/rest/v2/caches/${CACHE_NAME} 
----


For more information about using the REST endpoint, check the https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.1/html-single/data_grid_rest_api/index#rest_v2_create_cache[documentation].




=== Cache configuration using the Cache operator's CRD


WARNING: This feature is Tech Preview as of December, 2020. Use it for development purposes only.


The RHDG operator defines a new CRD (`Custom Resource Definition`) named `Cache`. This resource lets you set a cache configuration and add it to your DG cluster. 

For more information about this CRD, check the https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.1/html/running_data_grid_on_openshift/caches#creating_caches_operator-caches[official documentation]. 









== Consuming Data Grid: REST client

In some situations, you might want to test your RHDG cluster using REST prior to the more efficient alternative of the HotRod client. Data Grid servers provide RESTful HTTP access to data through a REST endpoint built on Netty.


WARNING: Make sure to have the env vars of Chapter 2.2 still defined.

Perform CRUD commands to interact with entries in the cache:
[source,bash]
----
# Create
curl -X POST -k -u developer:developer -H "Content-Type: text/plain" ${RHDG_URL}/rest/v2/caches/${CACHE_NAME}/0 --data "Hello World"
# Retrieve
curl -X GET -k -u developer:developer ${RHDG_URL}/rest/v2/caches/${CACHE_NAME}/0
# Update 
curl -X PUT -k -u developer:developer -H "Content-Type: text/plain" ${RHDG_URL}/rest/v2/caches/${CACHE_NAME}/0 --data "Hola mundo"
# Delete
curl -X DELETE -k -u developer:developer ${RHDG_URL}/rest/v2/caches/${CACHE_NAME}/0
----


For more information about the REST endpoint, check the https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.1/html-single/data_grid_rest_api/index#rest_v2_create_cache[documentation].






== Consuming Data Grid: HotRod Java client

Basically, there are two approaches for Java to interact with Red Hat Data Grid. You may use the Infinispan libraries directly or the Spring starter. Both approaches let you make the most out of your application:

* *Infinispan client*:  Access Data Grid remotely through the Hot Rod Java client API. Hot Rod Java clients give you high-performance remote access to Data Grid clusters.


* *Spring Boot starter*: Quickly get your Spring Boot project up and running with a set of managed transitive dependencies that include everything your Spring Boot project needs to seamlessly interact with Data Grid. This approach also enables you to to use *Spring Cache*.


For more information about the Infinispan client, check the following https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.1/html-single/data_grid_developer_guide/index[link]. To begin with the Spring starter, check this other https://access.redhat.com/documentation/en-us/red_hat_data_grid/8.1/html-single/data_grid_spring_boot_starter[link].





== Running your HotRod Java client

[WARNING]
==== 
The application needs at least a cache indexed. Use the following code:

[source, bash]
----
CACHE_NAME="indexed-cache"
curl -X POST -k -u developer:developer -H "Content-Type: application/json" ${RHDG_URL}/rest/v2/caches/${CACHE_NAME} --data-binary "@../caches/distributed-indexed.json"
----
For more information, check <<22-cache-configuration-using-the-rest-api,Cache Configuration section>>.
====

=== Running the client locally

Developing new functionality directly on OCP can be quite cumbersome due to the long time it takes to build a new version of the image after pushing changes. Therefore, the best way to test your application is running your application locally:

The default configuration of the application is prepared for the DG clusters created on Openshift using the operator (With SSL configured by default). To run it locally, specify a custom `application.properties` path:

[source, bash]
----
$ mvn clean package 
$ java -jar target/hotrod-tester-1.0.0.jar --spring.config.location=src/main/resources/application-local.properties
----

or, in one line:
[source, bash]
----
$ mvn clean spring-boot:run -Dspring-boot.run.arguments=--spring.config.location=src/main/resources/application-local.properties
----


=== Running the client on Openshift

Deploying your client application on OCP requires to create several Openshift objects. Therefore, we are going to define some common variables that will be used from now onwards:

[source, bash]
----
export app_name=rhdg8-hotrod-tester
export namespace=rhdg8
export datagrid_cluster=rhdg
export git_repo=https://github.com/alvarolop/rhdg8-client.git
----


First, create a ConfigMap that will store your application configuration:
[source, bash]
----
oc create configmap ${app_name}-config \
--from-file=application.properties=src/main/resources/application-k8s.properties \
--from-file=logback-spring.xml=src/main/resources/logback-spring-k8s.xml -n $namespace
----


Second, use an Openshift template to create your Openshift resources. There are two templates inside the `templates` folder:

* `rhdg-client.yaml`: Template that creates all the necessary OCP objects for your application. 
* `rhdg-client-ssl.yaml`: The same template but including the `.pem` file generated by the operator inside the client's container.

This is the command to apply the template on your cluster:
[source, bash]
----
oc process -f templates/rhdg-client.yaml -p APPLICATION_NAME=$app_name -p GIT_REPOSITORY=$git_repo -p APP_NAMESPACE=$namespace -p RHDG_CLUSTER_NAME=$datagrid_cluster | oc apply -f -
----


=== The application components


This application may be used to test many different features included in the Java implementation of Hot Rod protocol. All the tests and application logic is exposed via three REST endpoints:

* `api/basic`: Basic methods to test cache behavior: put, get, remove, restart, etc.
* `api/queries`: Methods to interact with an indexed cache to perform queries, bulk removes based on the result of queries and interact with cache indexes.
* `api/transaction`: Basic methods to test transactions.


=== Environment set up

If your client application is running on OCP, define these environment variables to simplify the following commands:
[source, bash]
----
APP_NAMESPACE="rhdg8"
APP_NAME="rhdg8-hotrod-tester"
APP_URL=$(oc get route ${APP_NAME} -n ${APP_NAMESPACE} -o template='http://{{.spec.host}}')
CACHE_NAME="distributed-01"
----

On the contrary, if your application is running locally, define these environment variables to simplify the following commands:
[source, bash]
----
APP_URL="http://localhost:8080"
CACHE_NAME="distributed-02"
----


=== Basic features

Basic operations:

[source, bash]
----
# Put bytes from 0 to 49
curl -k -G -X PUT "${APP_URL}/api/basic/cache/${CACHE_NAME}/bytes" -d size=1024 -d entries=50

# Put strings from 100 to 149
curl -k -G -X PUT "${APP_URL}/api/basic/cache/${CACHE_NAME}/string" -d minkey=100 -d entries=50

# Get Bulk from 100 to 149
curl -k -G -X GET "${APP_URL}/api/basic/cache/${CACHE_NAME}/bulk" -d minkey=100 -d entries=50

# Get byte entry 0
curl -k -G -X GET "${APP_URL}/api/basic/cache/${CACHE_NAME}/byte" -d key=0 -d show=true

# Get string entry 101
curl -k -G -X GET "${APP_URL}/api/basic/cache/${CACHE_NAME}/string" -d key=101 -d show=true

# Get keys
curl -k -G -X GET "${APP_URL}/api/basic/cache/${CACHE_NAME}/keys"

# Remove entries (From 10 to 110)
curl -k -G -X DELETE "${APP_URL}/api/basic/cache/${CACHE_NAME}" -d minkey=10 -d entries=100
----


=== Queries and indexes

TIP: These features are not tested against the cache `$CACHE_NAME`, but against a cache named `indexed-cache`. It is possible to modify the cache you are going to use in the `application.properties` file and restart the client application.





=== Transactions

ERROR: Work in progress









:sectnums!:




== Annex A: Managing SSL configuration

There are three options to manage SSL configuration for the Java HotRod client.

=== Option 1: Default configuration using operator

First option is to use the default configuration. This is the recommended option.

* The RHDG operator provides certificates by default in a secret with name `${RHDG_CLUSTER_NAME}-cert-secret`.
* Both the Spring Starter and the `infinispan-client-hotrod` accept a certificate in `.pem` format and build an in-memory KeyStore with all the certificates found under the path provided.

Add the following lines to your `application.properties` to configure the Infinispan Spring Starter:
[source, bash]
----
infinispan.remote.use-ssl=true
infinispan.remote.trust-store-path=config/tls.crt
infinispan.remote.sni-host-name=${RHDG_CLUSTER_NAME}.${CLUSTER_NAMESPACE}.svc
----

Add the following lines to your `application.properties` to configure the `infinispan-client-hotrod`:
[source, bash]
----
infinispan.client.hotrod.use_ssl=true
infinispan.client.hotrod.trust_store_path=config/tls.crt
infinispan.client.hotrod.sni_host_name=${RHDG_CLUSTER_NAME}.${CLUSTER_NAMESPACE}.svc
----

For more information about configuration parameters check the following resources:

* https://access.redhat.com/webassets/avalon/d/red-hat-data-grid/8.1/api/org/infinispan/client/hotrod/configuration/package-summary.html[RHDG 8.1 JavaDoc].
* https://github.com/infinispan/infinispan-spring-boot/blob/master/infinispan-spring-boot-starter-remote/src/test/resources/test-application.properties[Testing configuration of the Spring Starter].


=== Option 2: Custom truststore using Openssl

The second option is useful when you want custom certificates or you would like to access RHDG from outside your cluster.

The following commands are inspired in the blog https://github.com/infinispan/infinispan-image-artifacts/blob/9f028ddc1f5e26084b0b0edf46feb11ff3df2570/config-generator/src/main/groovy/org/infinispan/images/ConfigGenerator.groovy#L74-L77[code executed by the RHDG operator] to build SSL configuration from the server side.


[source, bash]
----
# Some variables
export CLUSTER_NAME=rhdg
export PCKS12_PASSWORD=changeit
export PCKS12_ALIAS=rhdg

# Get both tls secrets in .pem format 
oc get secret ${CLUSTER_NAME}-cert-secret -o jsonpath='{.data.tls\.key}' | base64 --decode > server.pem
oc get secret ${CLUSTER_NAME}-cert-secret -o jsonpath='{.data.tls\.crt}' | base64 --decode >> server.pem

# Create the PKCS file
openssl pkcs12 -export -passout env:PCKS12_PASSWORD -inkey tls.key -in tls.crt -name $PCKS12_ALIAS -out keystore.pkcs12
# Check that it worked
openssl pkcs12 -nokeys -info -in keystore.pkcs12 -passin pass:${PCKS12_PASSWORD}

# Convert to JKS
keytool -importkeystore -srckeystore keystore.pkcs12 -srcstoretype PKCS12 -destkeystore truststore.jks -deststoretype JKS -srcstorepass ${PCKS12_PASSWORD} -storepass ${PCKS12_PASSWORD}
# Create secret with the .jks file
oc create secret generic rhdg-client-truststore-secret --from-file=truststore.jks
----

After that, you would need to mount the `.jks` into the container and configure the JKS truststore (Similar as done in the previous option).

=== Option 3: initContainers

It is also possible to use initContainers to execute the commands of Option 2 before deploying the actual container of the application. Basically, you will have an initContainer that launches before the application container, executes the commands and  leaves the JKS file in any sort of persistent volume. After completion, the application container starts and uses the JKS as if it were already inside the container image.

For more information, please check this https://developers.redhat.com/blog/2017/11/22/dynamically-creating-java-keystores-openshift/[blog] from Red Hat Developers. This is the best option for clients or applications that do not accept certificates in `.pem` format. However, this solution forces you to use some kind of persistent in the containers.










== Annex B: Comparing cache definitions

Up until now, Red Hat Data Grid does not provide a mechanism to update cache definitions easily. Most of the configuration that you might apply to a cache needs a cache restart. Therefore, the REST API does not allow cache configurations update. You must delete it and create a new cache.

In addition to it, cache definitions retrieved with the REST API might not be identical to the definition used to create it. Data Grid adds, converts, and removes some of the parameters according to the default values.

The following commands show a mechanism to create a new cache, retrieve the modified configuration and check if it is similar or not.


If your DG is running on OCP, define these environment variables to simplify the following commands:
[source, bash]
----
CLUSTER_NAMESPACE="rhdg8"
CLUSTER_NAME="rhdg"
RHDG_URL=$(oc get route ${CLUSTER_NAME}-external -n ${CLUSTER_NAMESPACE} -o template='https://{{.spec.host}}')
CACHE_NAME="test-01"
----

On the contrary, if your DG is running locally, define these environment variables to simplify the following commands:
[source, bash]
----
RHDG_URL="https://localhost:11222"
CACHE_NAME="test-01"
----

Second, create your cache:
[source, bash]
----
curl -X POST -k -u developer:developer -H "Content-Type: application/json" ${RHDG_URL}/rest/v2/caches/${CACHE_NAME} --data-binary "@caches/test/$CACHE_NAME.json"
----

Third retrieve the configuration:
[source, bash]
----
curl -X GET -k -u developer:developer -H "Content-Type: application/json" ${RHDG_URL}/rest/v2/caches/$CACHE_NAME?action=config | jq > caches/test/$CACHE_NAME-output.json
----

Compare them using `jq`:
[source, bash]
----
jq --argfile a caches/test/$CACHE_NAME.json --argfile b caches/test/$CACHE_NAME-output.json -n '($a | (.. | arrays) |= sort) as $a | ($b | (.. | arrays) |= sort) as $b | $a == $b'
----

Delete the cache definition:
[source, bash]
----
curl -X DELETE -k -u developer:developer -H "Content-Type: application/json" ${RHDG_URL}/rest/v2/caches/$CACHE_NAME
----









== Annex C: Managing indexed caches

Indexed caches keep an index of the desired objects. Some operations update this index asynchronously. Therefore, there may be inconsistencies between the index and the real values stored in the cache. Use the following commands to clear and re-index your cache:

[source, bash]
----
curl -X POST -k -u developer:developer  ${RHDG_URL}/rest/v2/caches/distributed-01/search/indexes?action=clear
curl -X POST -k -u developer:developer  ${RHDG_URL}/rest/v2/caches/distributed-01/search/indexes?action=mass-index&mode=sync
----