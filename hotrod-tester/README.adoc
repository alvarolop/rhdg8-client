= HotRod tester
Álvaro López Medina <alopezme@redhat.com>
v1.0, 2020-12
// Create TOC wherever needed
:toc: macro
:sectanchors:
:sectnumlevels: 2
:sectnums:
:source-highlighter: pygments
:imagesdir: images
// Start: Enable admonition icons
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
ifndef::env-github[]
:icons: font
endif::[]
// End: Enable admonition icons
// Create the Table of contents here
toc::[]


TIP: This project is based on the work of @drhelius at https://github.com/drhelius/hotrod-tester

This project contains some varied examples that showcase useful configurations of RHDG Hot Rod client: Basic cache operations, queries, indexing, transactions, etc.





== Running the application

You can run this application locally or on OCP. These are the steps.


WARNING: The following sections assume that you have a Red Hat Data Grid 8.1 server cluster running either on OCP or locally. For more information about configuring your cluster, check the following https://github.com/alvarolop/rhdg8-server[link].


=== Running the client locally

Developing new functionality directly on OCP can be quite cumbersome due to the long time it takes to build a new version of the image after pushing changes. Therefore, the best way to test your application is running your application locally:

The default configuration of the application is prepared for the DG clusters created on Openshift using the operator (With SSL configured by default). To run it locally, specify a custom `application.properties` path:

[source, bash]
----
mvn clean package 
java -jar target/hotrod-tester-1.0.0.jar --spring.config.location=src/main/resources/application-local.properties
----

or, in one line:
[source, bash]
----
mvn clean spring-boot:run -Dspring-boot.run.arguments=--spring.config.location=src/main/resources/application-local.properties
----


=== Running the client on Openshift

Deploying your client application on OCP requires to create several Openshift objects. Therefore, we are going to define some common variables that will be used from now onwards:

[source, bash]
----
export app_name=rhdg8-hotrod-tester
export namespace=rhdg8
export datagrid_cluster=rhdg
export git_repo=https://github.com/alvarolop/rhdg8-client.git
export git_context=hotrod-tester
----


First, create two Config Maps that will store your application configuration:
[source, bash]
----
oc create configmap ${app_name}-file-config --from-file=./${git_context}/src/main/resources/application.properties -n $namespace
oc create configmap ${app_name}-logback-config --from-file=./${git_context}/src/main/resources/logback-spring.xml -n $namespace
[source, bash]
----


Second, use an Openshift template to create your Openshift resources.
[source, bash]
----
oc process -f templates/rhdg-client-ssl.yaml -p APPLICATION_NAME=$app_name -p GIT_REPOSITORY=$git_repo -p GIT_CONTEXT_DIR=$git_context -p APP_NAMESPACE=$namespace -p RHDG_CLUSTER_NAME=$datagrid_cluster | oc apply -f -
----








## 3. Usage

Set your cluster url:
[source, bash]
----
# These variables were already settled:
export app_name=<app_name>
export namespace=<namespace>

# These are new:
export cluster_url=<cluster_url>
export cache_name=default
----

[source, bash]
----
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/put/?entries=100000&minkey=0"
----

Usage examples:
[source, bash]
----
# PUT ASYNC
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/put/?entries=100000&minkey=0&async=true"
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/put/?entries=100000&minkey=100000&async=true"
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/put/?entries=100000&minkey=200000&async=true"

# GET ASYNC
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/get/?entries=100000&minkey=0&async=true"

# PUT SYNC
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/put/?entries=100000&minkey=0"
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/put/?entries=100000&minkey=100000"
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/put/?entries=100000&minkey=200000"
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/put/?entries=100000&minkey=300000"

# Test 10 entries
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/put/?entries=10&minkey=0"

# Obtain stats
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/stats"

# Get value of 1 entry
curl "http://${app_name}-${namespace}.${cluster_url}/api/cache/${cache_name}/get-single?key=0"
----




## 4. Testing RHDG images

Follow these steps:

[source, bash]
----
export CLIENT_URL=http://localhost:8081
export CACHE_NAME=bigcache
curl -G "${CLIENT_URL}/api/cache/${CACHE_NAME}/put" -d size=41943040 -d entries=1

curl -G "${CLIENT_URL}/api/cache/${CACHE_NAME}/get-single" -d key=0

# Get 50 times
for i in {1..50}; do echo "Time $i"; curl -G "${CLIENT_URL}/api/cache/${CACHE_NAME}/get-single" -d key=0 -d noshow=true; done

# Put 50 times
for i in {1..50}; do echo "Time $i"; curl -G "${CLIENT_URL}/api/cache/${CACHE_NAME}/put" -d size=41943040 -d entries=1; done

----



[source, bash]
----
# Fill the cache with 30k entries
curl -G "${CLIENT_URL}/api/cache/default/put-simple" -d entries=30 -d minkey=0 -d entrycontent=Test

curl -G "${CLIENT_URL}/api/cache/distributed-rest-01/put-simple" -d entries=30 -d minkey=0 -d entrycontent=Test

curl -G "${CLIENT_URL}/api/cache/distributed-rest-01/get-single-string" -d key=30

curl -G "${CLIENT_URL}/api/cache/distributed-rest-01/get-single-string" -d key="3"

# Retrieve some of the values
for ((i=1;i<=100;i++)); do echo "===> ENTRY $((i))"; curl -G "http://${app_name}-${namespace}.${cluster_url}/api/cache/default/get-single-string" -d key=$((i)); done


# Fill another cache with big key-values of type byte
curl -G "http://${app_name}-${namespace}.${cluster_url}/api/cache/default/put" -d entries=30000 -d minkey=40000 -d async=false -d size=10


# Retrieve some of the values
for ((i=1;i<=100;i++)); do echo "===> ENTRY $((40000+i))"; curl -G "http://${app_name}-${namespace}.${cluster_url}/api/cache/default/get-single" -d key=$((40000+i)); done


# Perform many requests in parallel
for ((i=1;i<=10;i++)); do curl -G "http://${app_name}-${namespace}.${cluster_url}/api/cache/default/get" -d entries=1000 -d minkey=40000 -d async=true; done
----


## 5. Debugging inside the pod

It is possible to enter into a pod and execute commands to check cache cluster stats:


[source, bash]
----
# Enter into the pod
$ oc rsh rhdg73-4-server-0

# Use the cli command line
$ /opt/datagrid/bin/cli.sh -c

# Check attributes of a cache
/subsystem=datagrid-infinispan/cache-container=clustered/distributed-cache=default:read-resource(include-runtime=true)
----


